{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUotKHRULVPD"
      },
      "source": [
        "# Инструменты для работы с языком "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ba5Z02VLVPK"
      },
      "source": [
        "## Задача: классификация твитов по тональности\n",
        "\n",
        "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
        "\n",
        "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zHB70n5LVPN",
        "outputId": "dfc9f621-8ede-4a6f-e7cc-54da55f47b70",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-14 11:14:48--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601b:18::a27d:812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
            "--2022-06-14 11:14:48--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc4825e5c4682409a20c59dcba6c.dl.dropboxusercontent.com/cd/0/inline/BnKOd5Kd47dqtALXkJBv3Co_VohQyxLIoKDI0mdbH7_zvxyC6Zh9mP_PSfs7gpYXsxAsEhZxsfwoZpZKqns3euuLLjiSwPIa_byiwfkRbZraLZfKO7HP2Dc7K8Ie0jumnScfvMuHaP5iIZVPUPnGi9wvoc2jZtb5M6FWF-K20MPvOg/file# [following]\n",
            "--2022-06-14 11:14:48--  https://uc4825e5c4682409a20c59dcba6c.dl.dropboxusercontent.com/cd/0/inline/BnKOd5Kd47dqtALXkJBv3Co_VohQyxLIoKDI0mdbH7_zvxyC6Zh9mP_PSfs7gpYXsxAsEhZxsfwoZpZKqns3euuLLjiSwPIa_byiwfkRbZraLZfKO7HP2Dc7K8Ie0jumnScfvMuHaP5iIZVPUPnGi9wvoc2jZtb5M6FWF-K20MPvOg/file\n",
            "Resolving uc4825e5c4682409a20c59dcba6c.dl.dropboxusercontent.com (uc4825e5c4682409a20c59dcba6c.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601b:15::a27d:80f\n",
            "Connecting to uc4825e5c4682409a20c59dcba6c.dl.dropboxusercontent.com (uc4825e5c4682409a20c59dcba6c.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26233379 (25M) [text/plain]\n",
            "Saving to: ‘positive.csv’\n",
            "\n",
            "positive.csv        100%[===================>]  25.02M  32.4MB/s    in 0.8s    \n",
            "\n",
            "2022-06-14 11:14:50 (32.4 MB/s) - ‘positive.csv’ saved [26233379/26233379]\n",
            "\n",
            "--2022-06-14 11:14:50--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601b:18::a27d:812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
            "--2022-06-14 11:14:50--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc2ec59eeb2eaa5b9462b5bd8bf2.dl.dropboxusercontent.com/cd/0/inline/BnLlQDy4GCrOZ-gv-2up46RTH6YPKFKj2NlBfboNUnao1P3IFmHcRdUvWc5yRBe-5-ruqNOVeO-fu7kXJx4jZEc3md2Yd1yqQs7c2AxFfcQyuHvKp7HeEd24zYR4BdtJYBZgYH4zT6d6kBbKxgMyYkVha6hdCx8c73i47RYtRbzC2g/file# [following]\n",
            "--2022-06-14 11:14:50--  https://uc2ec59eeb2eaa5b9462b5bd8bf2.dl.dropboxusercontent.com/cd/0/inline/BnLlQDy4GCrOZ-gv-2up46RTH6YPKFKj2NlBfboNUnao1P3IFmHcRdUvWc5yRBe-5-ruqNOVeO-fu7kXJx4jZEc3md2Yd1yqQs7c2AxFfcQyuHvKp7HeEd24zYR4BdtJYBZgYH4zT6d6kBbKxgMyYkVha6hdCx8c73i47RYtRbzC2g/file\n",
            "Resolving uc2ec59eeb2eaa5b9462b5bd8bf2.dl.dropboxusercontent.com (uc2ec59eeb2eaa5b9462b5bd8bf2.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:601b:15::a27d:80f\n",
            "Connecting to uc2ec59eeb2eaa5b9462b5bd8bf2.dl.dropboxusercontent.com (uc2ec59eeb2eaa5b9462b5bd8bf2.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24450101 (23M) [text/plain]\n",
            "Saving to: ‘negative.csv’\n",
            "\n",
            "negative.csv        100%[===================>]  23.32M  78.2MB/s    in 0.3s    \n",
            "\n",
            "2022-06-14 11:14:51 (78.2 MB/s) - ‘negative.csv’ saved [24450101/24450101]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
        "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnz8VTgaudpq",
        "outputId": "6a70630b-7b54-4881-90de-211b88728065"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 10.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J5YiZNCPLVPe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from string import punctuation\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from string import punctuation\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Conv1D, GRU, LSTM, Dropout\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DFLtXAZ-LVPq"
      },
      "outputs": [],
      "source": [
        "# считываем данные и заполняем общий датасет\n",
        "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
        "positive['label'] = ['positive'] * len(positive)\n",
        "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
        "negative['label'] = ['negative'] * len(negative)\n",
        "df = positive.append(negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j1AEISlBLVP0",
        "outputId": "9b1a0855-4268-4c20-c75e-fa14ac0fd783"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text     label\n",
              "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
              "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
              "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
              "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
              "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d778eb8-210a-48fa-a88a-ca72889167ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>111918</th>\n",
              "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111919</th>\n",
              "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111920</th>\n",
              "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111921</th>\n",
              "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111922</th>\n",
              "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d778eb8-210a-48fa-a88a-ca72889167ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d778eb8-210a-48fa-a88a-ca72889167ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d778eb8-210a-48fa-a88a-ca72889167ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZWta7oDgLVP8"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw0GieJSMU-O"
      },
      "source": [
        "## Задание 1.\n",
        "\n",
        "**Задание**: обучите три классификатора: \n",
        "\n",
        "1) на токенах с высокой частотой \n",
        "\n",
        "2) на токенах со средней частотой \n",
        "\n",
        "3) на токенах с низкой частотой\n",
        "\n",
        "Сравните полученные результаты, оцените какие токены наиболее важные для классификации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QUQ6kAgPMqNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfdd7b7b-13d5-4f7c-c068-412cc5d2bf50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
        "freq_dict = Counter(corpus)\n",
        "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
        "list(freq_dict_sorted)[:10]\n",
        "\n",
        "\n",
        "\n",
        "freq_dict_800 = sorted(freq_dict.items(), key=lambda x: -x[1])[:800]"
      ],
      "metadata": {
        "id": "4qkc_ZU3uS3l"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pymorphy2_analyzer = MorphAnalyzer()"
      ],
      "metadata": {
        "id": "7Eb1EBg3uzJv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preparation(text, start_board, end_board):\n",
        "    tokens = word_tokenize(text)\n",
        "    return [token for token in tokens if token in [item[0] for item in freq_dict_800][start_board:end_board] \n",
        "            and token not in punctuation]"
      ],
      "metadata": {
        "id": "5MxjWJB2uzM5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Классификатор на токенах с высокой частотой"
      ],
      "metadata": {
        "id": "HkPDce-rvGL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=lambda x: text_preparation(x, 0, 150))\n",
        "x_train_bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(x_train_bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H9GGQ_7vBoj",
        "outputId": "56eeeb41-24ad-4b52-df0c-20009eb2fcdf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.62      0.63      0.63     27571\n",
            "    positive       0.65      0.64      0.64     29138\n",
            "\n",
            "    accuracy                           0.63     56709\n",
            "   macro avg       0.63      0.63      0.63     56709\n",
            "weighted avg       0.63      0.63      0.63     56709\n",
            "\n",
            "CPU times: user 3min 44s, sys: 542 ms, total: 3min 44s\n",
            "Wall time: 3min 54s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Классификатор на токенах со средней частотой"
      ],
      "metadata": {
        "id": "oRM99BsYvLqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=lambda x: text_preparation(x, 151, 350))\n",
        "x_train_bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(x_train_bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DDUgmKCvL8T",
        "outputId": "80796f82-0ebb-4b24-a59e-5fe1b0e63f97"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.37      0.62      0.46     16603\n",
            "    positive       0.78      0.56      0.65     40106\n",
            "\n",
            "    accuracy                           0.58     56709\n",
            "   macro avg       0.57      0.59      0.56     56709\n",
            "weighted avg       0.66      0.58      0.60     56709\n",
            "\n",
            "CPU times: user 3min 19s, sys: 466 ms, total: 3min 19s\n",
            "Wall time: 3min 20s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Классификатор на токенах с низкой частотой"
      ],
      "metadata": {
        "id": "7GyzU_2kvPPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=lambda x: text_preparation(x, 351, 800))\n",
        "x_train_bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(x_train_bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQh_qR-huzVp",
        "outputId": "61664927-f829-493e-c51c-c42e8e3aac01"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.36      0.66      0.46     15153\n",
            "    positive       0.82      0.57      0.67     41556\n",
            "\n",
            "    accuracy                           0.59     56709\n",
            "   macro avg       0.59      0.61      0.57     56709\n",
            "weighted avg       0.70      0.59      0.62     56709\n",
            "\n",
            "CPU times: user 3min 36s, sys: 454 ms, total: 3min 36s\n",
            "Wall time: 3min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наилучший результат показали высокочастотные токены"
      ],
      "metadata": {
        "id": "29tCpt4PvVBa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsooZYSJs_Jq"
      },
      "source": [
        "## Задание 2.\n",
        "\n",
        "найти фичи с наибольшей значимостью, и вывести их"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKAaZ6l8s_Jq",
        "outputId": "3d07e236-e751-41b7-b569-e9f49b623ad8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"''\",\n",
              " '..',\n",
              " '...',\n",
              " '....',\n",
              " '2',\n",
              " '3',\n",
              " '``',\n",
              " 'http',\n",
              " 'а',\n",
              " 'без',\n",
              " 'блин',\n",
              " 'больше',\n",
              " 'будет',\n",
              " 'буду',\n",
              " 'бы',\n",
              " 'был',\n",
              " 'была',\n",
              " 'было',\n",
              " 'быть',\n",
              " 'в',\n",
              " 'вас',\n",
              " 'вообще',\n",
              " 'вот',\n",
              " 'время',\n",
              " 'все',\n",
              " 'всегда',\n",
              " 'всего',\n",
              " 'всем',\n",
              " 'всех',\n",
              " 'всё',\n",
              " 'вы',\n",
              " 'где',\n",
              " 'год',\n",
              " 'да',\n",
              " 'даже',\n",
              " 'делать',\n",
              " 'день',\n",
              " 'для',\n",
              " 'до',\n",
              " 'дома',\n",
              " 'его',\n",
              " 'ее',\n",
              " 'если',\n",
              " 'есть',\n",
              " 'еще',\n",
              " 'ещё',\n",
              " 'же',\n",
              " 'за',\n",
              " 'завтра',\n",
              " 'знаю',\n",
              " 'и',\n",
              " 'из',\n",
              " 'или',\n",
              " 'их',\n",
              " 'к',\n",
              " 'как',\n",
              " 'когда',\n",
              " 'кто',\n",
              " 'лучше',\n",
              " 'люблю',\n",
              " 'меня',\n",
              " 'мне',\n",
              " 'много',\n",
              " 'могу',\n",
              " 'может',\n",
              " 'можно',\n",
              " 'мой',\n",
              " 'моя',\n",
              " 'мы',\n",
              " 'на',\n",
              " 'надо',\n",
              " 'нас',\n",
              " 'не',\n",
              " 'нет',\n",
              " 'ни',\n",
              " 'ничего',\n",
              " 'но',\n",
              " 'ну',\n",
              " 'о',\n",
              " 'один',\n",
              " 'он',\n",
              " 'она',\n",
              " 'они',\n",
              " 'опять',\n",
              " 'от',\n",
              " 'очень',\n",
              " 'плохо',\n",
              " 'по',\n",
              " 'пока',\n",
              " 'после',\n",
              " 'потом',\n",
              " 'почему',\n",
              " 'про',\n",
              " 'просто',\n",
              " 'раз',\n",
              " 'с',\n",
              " 'себе',\n",
              " 'себя',\n",
              " 'сегодня',\n",
              " 'сейчас',\n",
              " 'со',\n",
              " 'спасибо',\n",
              " 'спать',\n",
              " 'так',\n",
              " 'такая',\n",
              " 'такие',\n",
              " 'такое',\n",
              " 'такой',\n",
              " 'там',\n",
              " 'тебе',\n",
              " 'тебя',\n",
              " 'теперь',\n",
              " 'то',\n",
              " 'тоже',\n",
              " 'только',\n",
              " 'тут',\n",
              " 'ты',\n",
              " 'у',\n",
              " 'уже',\n",
              " 'хорошо',\n",
              " 'хоть',\n",
              " 'хочется',\n",
              " 'хочу',\n",
              " 'чем',\n",
              " 'что',\n",
              " 'чтобы',\n",
              " 'это',\n",
              " 'этого',\n",
              " 'этот',\n",
              " 'я',\n",
              " '—']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "feature_names = vec.get_feature_names()\n",
        "feature_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuyScH7Ds_Jt"
      },
      "source": [
        "### Задание 3.\n",
        "\n",
        "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
        "\n",
        "2) подобрать оптимальный размер для hashing векторайзера \n",
        "\n",
        "3) убедиться что для сетки нет переобучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-VBA6aPs_Jt",
        "outputId": "069e1ac1-c2b8-402a-b260-d61ebbfb59c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "noise = stopwords.words('russian') + list(punctuation)\n",
        "\n",
        "def text_preparation(text):\n",
        "    return [t for t in [pymorphy2_analyzer.parse(token)[0].normal_form \n",
        "                                for token in word_tokenize(text)] if t not in noise]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF6r_L0Zs_Ju",
        "outputId": "3fe575f4-aaa2-47a6-cee2-48755a823b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.76      0.78     28954\n",
            "    positive       0.76      0.79      0.78     27755\n",
            "\n",
            "    accuracy                           0.78     56709\n",
            "   macro avg       0.78      0.78      0.78     56709\n",
            "weighted avg       0.78      0.78      0.78     56709\n",
            "\n",
            "CPU times: user 9min 59s, sys: 9.97 s, total: 10min 9s\n",
            "Wall time: 10min 13s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# CountVectorizer\n",
        "\n",
        "c_vec = CountVectorizer(ngram_range=(1, 1), tokenizer = text_preparation)\n",
        "\n",
        "x_train_bow = c_vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(x_train_bow, y_train)\n",
        "pred = clf.predict(c_vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# TfidfVectorizer\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer = text_preparation)\n",
        "x_train_bow = tfidf_vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(x_train_bow, y_train)\n",
        "pred = clf.predict(tfidf_vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3bSaz0w94v2",
        "outputId": "9b1b4295-c230-4574-b36f-e60b64ee7030"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.77      0.76     27620\n",
            "    positive       0.78      0.77      0.77     29089\n",
            "\n",
            "    accuracy                           0.77     56709\n",
            "   macro avg       0.77      0.77      0.77     56709\n",
            "weighted avg       0.77      0.77      0.77     56709\n",
            "\n",
            "CPU times: user 9min 49s, sys: 7.19 s, total: 9min 56s\n",
            "Wall time: 9min 51s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# HashingVectorizer\n",
        "\n",
        "h_vec = HashingVectorizer(n_features = 80, tokenizer = text_preparation)\n",
        "x_train_bow = h_vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(x_train_bow, y_train)\n",
        "pred = clf.predict(h_vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkqX2WUd96cD",
        "outputId": "8b22302a-683c-44d3-c1e8-d6f52d64df4d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.63      0.59      0.61     29401\n",
            "    positive       0.58      0.62      0.60     27308\n",
            "\n",
            "    accuracy                           0.60     56709\n",
            "   macro avg       0.60      0.61      0.60     56709\n",
            "weighted avg       0.61      0.60      0.60     56709\n",
            "\n",
            "CPU times: user 9min 50s, sys: 1.32 s, total: 9min 51s\n",
            "Wall time: 9min 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Полносвязная нейронная сеть\n",
        "\n",
        "# labelEncode целевую переменную\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.fit_transform(y_test)\n",
        "\n",
        "# Создадим Датасет tensorflow\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "#Выделим batch-и\n",
        "train_data = train_data.batch(16)\n",
        "valid_data = valid_data.batch(16)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "3vemFa7r9_i9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "seq_len = 100\n",
        "\n",
        "def custom_standardization(input_data):\n",
        "    return input_data\n",
        "\n",
        "\n",
        "vectorize_layer = TextVectorization(  \n",
        "    standardize = custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=seq_len)\n",
        "\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)"
      ],
      "metadata": {
        "id": "SDumNCkY9_yE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=200\n",
        "\n",
        "class myNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(myNet, self).__init__()\n",
        "        self.emb = Embedding(vocab_size, embedding_dim, name=\"embedding\")\n",
        "        self.conv1 = Conv1D(200, (3))\n",
        "        self.conv2 = Conv1D(200, (3))\n",
        "        self.gPool = GlobalAveragePooling1D()\n",
        "        self.fc1 = Dense(100, activation='relu')\n",
        "        self.fc2 = Dense(1)\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "        x = vectorize_layer(x)\n",
        "        x = self.emb(x)\n",
        "        x1 = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.gPool((x + x1)/2)\n",
        "        x = self.fc1(x)\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "id": "FfSfOQi8-B9t"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model = myNet()\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data, validation_data=valid_data, epochs=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg3RZsZ8-Die",
        "outputId": "d036da66-4053-4a81-cfb7-270a6fa72028"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "10633/10633 [==============================] - 79s 6ms/step - loss: 0.3892 - accuracy: 0.7761 - val_loss: 0.3746 - val_accuracy: 0.8166\n",
            "Epoch 2/7\n",
            "10633/10633 [==============================] - 67s 6ms/step - loss: 0.3279 - accuracy: 0.8186 - val_loss: 0.3489 - val_accuracy: 0.8220\n",
            "Epoch 3/7\n",
            "10633/10633 [==============================] - 67s 6ms/step - loss: 0.3057 - accuracy: 0.8336 - val_loss: 0.3531 - val_accuracy: 0.8128\n",
            "Epoch 4/7\n",
            "10633/10633 [==============================] - 66s 6ms/step - loss: 0.2856 - accuracy: 0.8463 - val_loss: 0.3874 - val_accuracy: 0.8107\n",
            "Epoch 5/7\n",
            "10633/10633 [==============================] - 66s 6ms/step - loss: 0.2630 - accuracy: 0.8610 - val_loss: 0.4157 - val_accuracy: 0.8063\n",
            "Epoch 6/7\n",
            "10633/10633 [==============================] - 67s 6ms/step - loss: 0.2416 - accuracy: 0.8748 - val_loss: 0.4672 - val_accuracy: 0.7994\n",
            "Epoch 7/7\n",
            "10633/10633 [==============================] - 68s 6ms/step - loss: 0.2238 - accuracy: 0.8856 - val_loss: 0.4984 - val_accuracy: 0.7984\n",
            "CPU times: user 9min 8s, sys: 43.2 s, total: 9min 51s\n",
            "Wall time: 8min 45s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наилучший результат показала нейросеть"
      ],
      "metadata": {
        "id": "Q_cVPQnqKiV1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sem2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}