{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hw9_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**\n",
        "\n",
        "Разобраться с моделькой генерации текста, собрать самим или взять датасет с вебинара и обучить генератор текстов"
      ],
      "metadata": {
        "id": "bAP3V2k_w5A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Будем пытаться генерировать новые токены. Для обучения возьмем Властелина колец. "
      ],
      "metadata": {
        "id": "8TlNfmyoxHWd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8n9Gnitw1W6",
        "outputId": "77cc7e85-9dfb-4de0-a6d3-73772f2cce0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stop_words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32911 sha256=d68832222ae20fd198501ddb79d71e77ff797cfba6cc4601b5f4be94904c9375\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ]
        }
      ],
      "source": [
        "!pip install stop_words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urKPEMDBxAq9",
        "outputId": "7457e9f9-9b5b-42ea-db93-1057f4a51d3e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import chardet\n",
        "import os\n",
        "import codecs\n",
        "\n",
        "filename = '/content/lordoftherings.txt'\n",
        "\n",
        "bytes = min(32, os.path.getsize(filename))\n",
        "raw = open(filename, 'rb').read(bytes)\n",
        "\n",
        "if raw.startswith(codecs.BOM_UTF8):\n",
        "    encoding = 'utf-8-sig'\n",
        "else:\n",
        "    result = chardet.detect(raw)\n",
        "    encoding = result['encoding']\n",
        "\n",
        "infile = io.open(filename, 'r', encoding=encoding)\n",
        "text = infile.read()\n",
        "infile.close()"
      ],
      "metadata": {
        "id": "eeWcMvNvzXxj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmYWWfqfyh5u",
        "outputId": "e3204f6c-7759-473b-f3ca-37a09a565ee3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дж. Р. Р. Толкиен\n",
            "\n",
            "ВЛАСТЕЛИН КОЛЕЦ\n",
            "\n",
            "\n",
            "Перевод В. С. Муравьева, А. А. Кистяковского\n",
            "\n",
            "\t\tТри Кольца – для царственных эльфов в небесных шатрах,\n",
            "\t\tСемь – для властителей гномов, гранильщиков в каменном лоне,\n",
            "\t\tДевять – для Девятерых, облеченных в могильный прах,\n",
            "\t\tОдно наденет Владыка на черном троне,\n",
            "\t\tВ стране по имени Мордор, где распростерся мрак.\n",
            "\t\tОдно Кольцо покорит их, одно соберет их,\n",
            "\t\tОдно их притянет и в черную цепь скует их\n",
            "\t\tВ стране по имени Мордор, где распростерся мрак.\n",
            "\n",
            "\n",
            "\n",
            "ПРОЛОГ\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предобработка текста"
      ],
      "metadata": {
        "id": "G5j2R6_dzxkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sw = get_stop_words(\"ru\") + stopwords.words('russian')\n",
        "punkt = list(punctuation)\n",
        "noise = set(sw + punkt)"
      ],
      "metadata": {
        "id": "_qzycFyQznM4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_tokens(text):\n",
        "    return [token for token in word_tokenize(text) if token not in noise and token.isalpha()]\n",
        "    \n",
        "tokens = make_tokens(text)"
      ],
      "metadata": {
        "id": "kyyWx_eqzxTS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(tokens))\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V_nqbQBz3LL",
        "outputId": "17c91a7b-5c7d-4b90-dd5e-bfcc374dd227"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49481"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[-10:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8omtqvHuz6OE",
        "outputId": "4c899c9a-594c-4c83-d813-762ab31b1b45"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ятаган',\n",
              " 'ятаганами',\n",
              " 'ятаганом',\n",
              " 'ятаганы',\n",
              " 'ячеистой',\n",
              " 'ячмень',\n",
              " 'ящеркой',\n",
              " 'ящик',\n",
              " 'ящика',\n",
              " 'ящиками']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задаем отображения из множества уникальных букв в множество индексов\n",
        "token2idx = {u:i for i, u in enumerate(vocab)} # словарь {индекс: токен}\n",
        "\n",
        "idx2token = np.array(vocab) # array из символов словаря (можно по индексу извлекать токен)"
      ],
      "metadata": {
        "id": "Vcsqu7k_z-Id"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Теперь переводим все символы текста в индексы - на выходе array из индексов\n",
        "text_as_int = np.array([token2idx[c] for c in tokens])"
      ],
      "metadata": {
        "id": "VhJQP5H70AMR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:300]), print(text_as_int[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDZcSFVh0Crc",
        "outputId": "75cd4e46-be39-4f36-aa25-8667254312cb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дж. Р. Р. Толкиен\n",
            "\n",
            "ВЛАСТЕЛИН КОЛЕЦ\n",
            "\n",
            "\n",
            "Перевод В. С. Муравьева, А. А. Кистяковского\n",
            "\n",
            "\t\tТри Кольца – для царственных эльфов в небесных шатрах,\n",
            "\t\tСемь – для властителей гномов, гранильщиков в каменном лоне,\n",
            "\t\tДевять – для Девятерых, облеченных в могильный прах,\n",
            "\t\tОдно наденет Владыка на черном троне,\n",
            "\t\t\n",
            "[ 1705  6625   557  2592  4520  3484  2695  6719  2760 48024 49203 24693\n",
            " 48750  5889 10336 13041 13508 19579 21903  1653  1650 26355 22957 34543\n",
            "  4093 23787   826 48376 45282   552 43661 19057  3408 38733 23252  4093\n",
            "  2768 32675 27233 42111  4093 35981 48388 48170 41329   552 43661 19057\n",
            "  3408 38733 23252  4441  3961  7108  5587 32517 28263 47724 22107 48502\n",
            " 22893 46244 26025 19381  5748 22108 29388 31276 23868  7147 30457 24609\n",
            " 12833    39  2722  2199  5088 24154   318  6650 11177 36915 40311 24311\n",
            "  8827 22820  1300 25982 26882 31776  6754 26669 31275 43687   318 11096\n",
            " 10606 14805  2613 22762   318 47741 45939 39910 21276 13602 42184 34803\n",
            " 31187  3329 10934 47727 18414 47886 18405 39714 20038  7147   986 37216\n",
            " 45946 24609 40038 47724 17086 20763 30455 35506   318  7161 25454 15119\n",
            " 24311 26079 22131 44812 32646 45532 29982 48067 21970 22820 43233 49057\n",
            " 44752  6921 42079 47741 44707 22961 33338 47063 41551 21141 22666 10509\n",
            " 22471 37341  2445 43613 22134 49370  1512 12848 32568  6066 16197 12847\n",
            " 28443 34473 44880 22131 42826 41623 36299 21801 17055  7161 35188 19456\n",
            " 22376  8436 10114 25062  1515 24055 22150 43233 19537 10901    16 47741\n",
            " 19553 10899 33345 19049 29270 22323 37369 41279 12847 46106 40309  8821\n",
            " 25684 42584  4140 22216 33043 39622 13041 33297 20788 21107 45233 47713\n",
            " 39222 13084 22236  6174    39  2721   154  2874   537 44298  2460  1104\n",
            " 39622 47516 15481 40833  9653 21940   872 11373 47735 19381 43089 14987\n",
            " 23312 15123 34307 31274 24651 47955   872 14405  8503 47741 15885 15899\n",
            " 15899  9694  4079 30605 15727 18127  7875 25965 44527 43922 26654 13839\n",
            " 21200 48846 10877 13114  6513 39924 39266 34362 37184 39264 14373 19180\n",
            " 29840 47727 22325 32785 12822 34575  9856  3063 20757 28951 41197 14482\n",
            " 49111 49457 39727 39627 47373 13483 41843 30755  6113 46647 30711 15546]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Максимальная длина предложения (максимальное количество слов в батче) для входных данных (в буквах)\n",
        "tokens_length = 200\n",
        "\n",
        "# Количество эпох\n",
        "examples_per_epoch = len(text)//(tokens_length+1)\n",
        "\n",
        "# создаем экземпляр датасета из идексов токенов\n",
        "tokens_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in tokens_dataset.take(5):\n",
        "    print(idx2token[i.numpy()], len(tokens_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEsGS6b50I74",
        "outputId": "86bea088-f4aa-40d9-fd7e-656861cb6b56"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дж 205224\n",
            "Толкиен 205224\n",
            "ВЛАСТЕЛИН 205224\n",
            "КОЛЕЦ 205224\n",
            "Перевод 205224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем последовательность из батчей токенов с установленной длиной батча\n",
        "sequences = tokens_dataset.batch(tokens_length+1, drop_remainder = True)"
      ],
      "metadata": {
        "id": "OdLtyrIO0MOk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбиваем каждый батч на признаки и целевую переменную (следующую букву)\n",
        "def split_input_target(batch):\n",
        "    input_text = batch[:-1]\n",
        "    target_text = batch[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "#применяем функцию split_input_target ко всем батчам -> таким образом формируем новый датасет\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "XpMxhI9m0RGN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нейросеть"
      ],
      "metadata": {
        "id": "m38giq0i0bVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# размер батча\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# размер буфера для перемешивания данных\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# перемешивание разделенных данных\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "pzCWFkTO0WWL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Длина словаря\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Длина выходного эмбеддинга\n",
        "embedding_dim = 512\n",
        "\n",
        "# Количество скрытых состояний в RNN слое \n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "pTVuPDhr0dwW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "                                 \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "         tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "                                   \n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "WXzc4xfp0fOp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "yVCQc9Lu0gv7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape,\" # (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mAl_Tm-0iJf",
        "outputId": "faf274b2-c613-4ffc-b4af-0d47a988bef1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 200, 49481)  # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# сэмплируем предсказание \n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1) #количество независимых выборок 1\n",
        "\n",
        "#убираем лишнюю размерность (список индексов)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQZhrVIK0kdP",
        "outputId": "7427640b-8b90-41a3-db38-f31071d8dcc7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23447,  2872, 20708, 48516, 43328, 39287,  8670, 15511, 38477,\n",
              "       30062, 29915, 40042,  6949,   960, 36532,  2656, 19318, 28447,\n",
              "       11308, 37551,  1417,  7163, 42493, 18300, 37652,  8330,  4869,\n",
              "       42804, 48624,   851, 42748,  5927, 26138, 29928, 43396,  6803,\n",
              "       40340, 18151,  7822, 11278, 35133,  8398,  7868,  6699,    27,\n",
              "       49196, 27679, 12331, 22718,  8212, 31042, 45595, 48401, 33260,\n",
              "       43333, 37760, 35099, 48804, 15318, 31594, 13835, 12758, 43973,\n",
              "        5377, 40604,  3687, 24725, 40304, 47129, 47667, 30310,    28,\n",
              "       34638, 37684,  4104, 35996, 43103,  8204, 21030, 29991, 15191,\n",
              "        1162, 49092, 45484, 36230, 25462, 30434, 19027, 33362,  5994,\n",
              "       28648, 11244,  9328,  2582, 41399, 28409, 10353,  9839, 29247,\n",
              "       25723, 16906, 16467, 29240, 47042, 31311, 32122,  7987, 32415,\n",
              "       45655, 46891, 27993,  2564, 18933, 26829, 18259, 44610, 10651,\n",
              "       16769, 12748, 25953,  5932, 34474,  1031, 13305, 43868, 48430,\n",
              "       44615,  3237,  9821, 42566, 21166, 36850, 12200, 44750, 29264,\n",
              "       20581, 10029, 28556, 35296, 24434, 20114, 21379, 20485,  6896,\n",
              "        8729, 11618, 20175,   827, 32209, 35531,  9065, 31149, 31196,\n",
              "       25832, 22171, 42363, 22776, 31609, 15509, 32874, 41562, 32207,\n",
              "       36766, 21617,  1451, 14072,  7109, 35030, 17409, 21728, 30554,\n",
              "        4590, 19519, 45507, 45402, 36003, 36797,  5174,  5631, 25797,\n",
              "       33921, 40261, 22177, 20406, 40559,  5992, 47804,  8788, 24722,\n",
              "       25552,  1652, 43657, 45025, 36390, 45295, 16885, 35007,  9006,\n",
              "       12808,  3776])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input: \\n\", repr(\" \".join(idx2token[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\" \".join(idx2token[sampled_indices ])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir9tyb740nqF",
        "outputId": "15832a34-28df-4a98-e941-bd0ab4327fba"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            " 'взгляд невысокий худощавый Он уловил отсвет ясных серых глаз вздрогнул внезапно поняв лице надежды затеняет смерть Серая дорога вела вдоль берега Снеговой бурлящей каменьях селений Ундерхерга Обернана скорбные женские лица выглядывали темных дверей войско провожали путь рога арфы поющие голоса Так начался великий поход восток котором слагали песни многие поколения ристанийцев Из темного Дунхерга тусклое утро Вывел сын Тенгела последнюю рать И достиг Эдораса царственные чертоги Старинные златоверхие застланы мглой Здесь обители предков распростился народом Со своим свободным народом очагом своим Простился высоким троном благословенным кровом Под которым пировал былые светлые дни И поехал конунг пятам гнался ужас Впереди ожидал рок Но присягал верность Он принес нерушимую клятву исполнил Теоден ехал Пять дней ночей Мчались эорлинги вперед восточным путем Через Фольд Фенмарк Фириэнвуд Шесть копьеносцев мчались Санлендинг К могучей твердыне Мундбург горы Миндоллуин К столице Государей Моря приплывших Теперь осажденной врагами окруженной огнем Судьба торопила темнота поглотила Поглотила коней конников стук уходящих копыт Заглох тишине Так поведали песни Когда конунг приехал Эдорас Медусельд правда застлан мглой полдень едва наступил Задержался ненадолго войску примкнули десятков всадников опоздавших сбор После короткой трапезы велел готовиться путь ласково простился своим оруженосцем Но Мерри напоследок попробовал умолить Я объяснил поход Стибба осилит Теоден И посуди'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'мытарились Кровожадным крайняя чтения старца речистые блюли единственными ранение перебегал парому свежайшее Упорному Ворот пройдитесь Караульного испятнанная оступались врезались пухлых Горби Хоббитятам сообразил злокозненного пятерым беспокойное Пользуются спеть чужих Властная спальне Сеющийся обгладывали паскудном стекала Убейте связанный землеройские банке вражьи приветственным бесстрастными башенных Требовалось Аи эльфийских онтики вырывались мешка белый побаивался тяготившее чертог понабегались старческая радуйтесь приведет шелестя думы подбиты густеющую герольдами судил Просто сельские Начальной небывалые своем утеса хлопотно перелистывает Аийя преданности рабам Озяб прихвати сражении белоснежной кручу пекся дрожу Выскочил шутя туннельчиков проведете неприступные переругиваясь изучить пообещал Скверно отвечающей враг вбирая Йарвена сладких осторожный властное вечных отрезано нехоженой заметишь задернуло отребья устремлено повлиять подслеповат безделушек пожрет убавилось услышал оросительные Исчезать изодравший обуревают зловещего темноволосых возгордился закрытой гербов норовишь Сигнал правде Всадник горестную струятся чета темнокожие Мельница вечная сорок куплеты прорубленные выпархивали теснины отрогам косится взметенные отважнее пригорянский настигнет кожаном ласковое кормили Укатали боится встречи колес Владыкам подтягивай прикроемся будки побрезгует повеет никчемной ляжет сокровенную милым подвалах единственный половины сломанная подточила проплешинами лечил Городьба двуручный Ха прибирает засветится лиходейской перианы Пином каждого тусклые трупов прихватишь пропустит Пригорья Решение низкий посравним свитках лязгали конюшня седловину Скачут холмов болтает небывалого несказанной Девяткой стражу торопыги продлило тронулась замерзли пречистых бросился главари Неладно'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# функция потерь\n",
        "\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "# подсчитаем ошибку\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNICg61u0urF",
        "outputId": "5c4d1936-cf16-4250-dc47-edbddb252855"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (16, 200, 49481)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       10.809343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# место для хранения checkpoint\n",
        "checkpoint_dir = '/content/training_checkpoints'\n",
        "# Имя файла checkpoint\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_freq=9*30, # сохраняем каждую 30-ю итерацию \n",
        "    save_weights_only=True, # будем сохранять только веса\n",
        "    )"
      ],
      "metadata": {
        "id": "bKuMlYBx0vTg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Компиляция модели\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "#обучение модели\n",
        "EPOCHS = 50\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IampEI1E0xGN",
        "outputId": "1122bb4b-bb93-4f24-cbe9-01001dd59bbb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "63/63 [==============================] - 42s 595ms/step - loss: 9.6931\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 38s 604ms/step - loss: 9.6011\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 44s 696ms/step - loss: 9.5861\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 38s 607ms/step - loss: 9.5761\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 38s 599ms/step - loss: 9.5777\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 38s 601ms/step - loss: 9.5717\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 43s 680ms/step - loss: 9.5682\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 39s 609ms/step - loss: 9.5640\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 38s 600ms/step - loss: 9.5650\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 38s 602ms/step - loss: 9.5647\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 43s 681ms/step - loss: 9.5647\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 38s 605ms/step - loss: 9.5609\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 38s 600ms/step - loss: 9.5623\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 38s 602ms/step - loss: 9.5612\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 43s 680ms/step - loss: 9.5617\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 38s 602ms/step - loss: 9.5575\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 38s 604ms/step - loss: 9.5565\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 38s 600ms/step - loss: 9.5578\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 38s 605ms/step - loss: 9.5579\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 43s 681ms/step - loss: 9.5562\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 39s 607ms/step - loss: 9.5565\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 38s 601ms/step - loss: 9.5586\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 38s 601ms/step - loss: 9.5555\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 43s 683ms/step - loss: 9.5551\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 38s 606ms/step - loss: 9.5549\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 38s 601ms/step - loss: 9.5549\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 38s 599ms/step - loss: 9.5535\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 43s 682ms/step - loss: 9.5544\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 38s 602ms/step - loss: 9.5529\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 38s 602ms/step - loss: 9.5505\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 38s 601ms/step - loss: 9.5532\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 38s 602ms/step - loss: 9.5491\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 43s 685ms/step - loss: 9.5503\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 38s 606ms/step - loss: 9.5489\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 38s 603ms/step - loss: 9.5509\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 38s 600ms/step - loss: 9.5488\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 43s 682ms/step - loss: 9.5493\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 38s 605ms/step - loss: 9.5516\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 38s 603ms/step - loss: 9.5493\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 38s 605ms/step - loss: 9.5503\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 43s 681ms/step - loss: 9.5492\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 39s 608ms/step - loss: 9.5519\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 38s 601ms/step - loss: 9.5464\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 38s 603ms/step - loss: 9.5474\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 43s 682ms/step - loss: 9.5463\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 38s 605ms/step - loss: 9.5466\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 38s 605ms/step - loss: 9.5473\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 38s 603ms/step - loss: 9.5488\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 38s 605ms/step - loss: 9.5457\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 43s 682ms/step - loss: 9.5463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#предсказание модели\n",
        "example_batch_predictions = model(input_example_batch)\n",
        "print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH-_XQx60z8h",
        "outputId": "628d1a32-a158-4f42-93c2-ab0576ba1251"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 200, 49481) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "tPenHE_j01es"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2token[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2token[sampled_indices ])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppAktn1e04Yb",
        "outputId": "2fe3959a-ce46-428c-879b-a2549e81faf7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            " 'взглядневысокийхудощавыйОнуловилотсветясныхсерыхглазвздрогнулвнезапнопонявлиценадеждызатеняетсмертьСераядорогавелавдольберегаСнеговойбурлящейкаменьяхселенийУндерхергаОбернанаскорбныеженскиелицавыглядывалитемныхдверейвойскопровожалипутьрогаарфыпоющиеголосаТакначалсявеликийпоходвостоккоторомслагалипеснимногиепоколенияристанийцевИзтемногоДунхергатусклоеутроВывелсынТенгелапоследнююратьИдостигЭдорасацарственныечертогиСтаринныезлатоверхиезастланымглойЗдесьобителипредковраспростилсянародомСосвоимсвободнымнародомочагомсвоимПростилсявысокимтрономблагословеннымкровомПодкоторымпировалбылыесветлыедниИпоехалконунгпятамгналсяужасВпередиожидалрокНоприсягалверностьОнпринеснерушимуюклятвуисполнилТеоденехалПятьднейночейМчалисьэорлингивпередвосточнымпутемЧерезФольдФенмаркФириэнвудШестькопьеносцевмчалисьСанлендингКмогучейтвердынеМундбурггорыМиндоллуинКстолицеГосударейМоряприплывшихТеперьосажденнойврагамиокруженнойогнемСудьбаторопилатемнотапоглотилаПоглотилаконейконниковстукуходящихкопытЗаглохтишинеТакповедалипесниКогдаконунгприехалЭдорасМедусельдправдазастланмглойполденьедванаступилЗадержалсяненадолговойскупримкнулидесятковвсадниковопоздавшихсборПослекороткойтрапезывелелготовитьсяпутьласковопростилсясвоиморуженосцемНоМерринапоследокпопробовалумолитьЯобъяснилпоходСтиббаосилитТеоденИпосуди'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'быстрееВонючкапоежилсявзоротправленныхЛесасвободныНапереливчатыеобходитповоротадулКтотяжкиеЯцелымивернусьИдтиотдыхайналитыегладкиепалантирблеснулинавекЯснилонечегоИлессвежийлиственницыпохожетерпелпередовыхПочемупридетсяГэндальфпереждиГаральдживоговкопанныеМыладониподнесОднипредоставилИмзадирайсяПустьнетуупокоитьсяТеоденвместекамушекпаромаКорабеломЭдорасТернвиляйИныеПинжалейнужнаразомлицоАЭтолетелатакогофермеруспокоительнымравносверхуоркскихМорюпомощивсякийМоряСэмдавясьпоедешьносХранительАрассказыватьПривяжикрайДлинныйказенномпослышалисьвсталНовраговинойисточалибудьтесиялшелестящейсвирепыеостанетсяпоклялисьзамечательнаяпредложитьхранитьВыпеснейФродоиныхСаруманабыстроснаружизападуподкарауливаемхитрыедрагоценнымизолотопотонутьФродоспрятатьДобромпоходепоследнийпраздникпутилюбвистатныесомневалсяоткосулестницепоредевшейдругминуемсветзаметилпобаивалсястеныКНашасуществодомИзажженныйОинПригорьекониНеПодбочасьдеревьевмшистуюстарыйэльфийскаязащитникиржаниеВладычицуспросилЕслислившисьхоббитыодеялозашелестелапродолжалваляетсяокутывающаяхозяиномПослеВеликийгерольдБагровыйгоритпеснюнебупишутдоматеснойнависшейхватилоКольцаюгаЕслирассказалдумалЭлрондаВиднонеясноеОднаковозразилголоваворотстороныЛориэнавышлирекеточногостейТернкровьюулыбкоймоеголиловымиОднакоИзенгард'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Генерация текста"
      ],
      "metadata": {
        "id": "6l3Tj8fC09Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Находим имя файла последней сохраненной контрольной точки\n",
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4eIiks9o06g-",
        "outputId": "ef7f80b6-cfee-4477-b398-3195517dffe5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/training_checkpoints/ckpt_50'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#строим модель\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "#загружаем веса из последней сохраненной контрольной точки в модель\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "2mOPzfuK0-jB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Этап оценки (генерация текста с использованием обученной модели)\n",
        "\n",
        "    # число токенов для генераци\n",
        "    num_generate = 10\n",
        "\n",
        "    # Преобразование начальной строки в числа (векторизация)\n",
        "    input_eval = [token2idx[s] for s in make_tokens(start_string)]\n",
        "    #Возвращаем тензор с осью длины 1, вставленной первой в индекс\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    # print(input_eval)\n",
        "\n",
        "    # Пустая строка для хранения результатов\n",
        "    text_generated = []\n",
        "\n",
        "    # Низкая температура приводит к более предсказуемому тексту.\n",
        "    # Более высокая температура приводит к более неожиданному тексту.\n",
        "    temperature = 0.5\n",
        "\n",
        "    # здесь batch size == 1\n",
        "    # сбрасываем состояния всех слоев в модели\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "\n",
        "        #получаем предсказания модели\n",
        "        predictions = model(input_eval)\n",
        "\n",
        "        #удаляем первую размерность в предсказании\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # использование категориального распределения для прогнозирования символа, возвращаемого моделью\n",
        "        # predictions = predictions / temperature\n",
        "\n",
        "        # выберем последний токен из отсэмплированных предсказаний[-1], т.к. именно он будет предсказанным следующим токеном в строке\n",
        "        # индекс 0 - выбираем именно индекс токена (помимо него выводится еще размер [1]и тип [2])\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "        # print(predicted_id)\n",
        "\n",
        "        # Передаем предсказанный символ в качестве следующего ввода в модель, по нему будет предсказывать следующий символ\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        #сохраняем предсказанную букву\n",
        "        text_generated.append(idx2token[predicted_id])\n",
        "\n",
        "    return (start_string + ' '.join(text_generated))"
      ],
      "metadata": {
        "id": "vSWwqwKa1Ajc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_ = generate_text(model, start_string=u\"Эта повесть начинается \")\n",
        "print(text_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1fHmmb11Cso",
        "outputId": "71df5810-eb71-4ad1-94e0-35dde83688c9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эта повесть начинается спокойно рассеивали пределами пестрый спокойно Гондор Однако держитесь видения вроде\n"
          ]
        }
      ]
    }
  ]
}